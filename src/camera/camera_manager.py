# /home/pi/autocarz/src/camera/camera_manager.py
# YOLO,openCV ìƒ‰ìƒ ë° í¬ê¸° êµ¬ë¶„ ê¸°ëŠ¥ ì¶”ê°€

import cv2
import time
import platform
from threading import Lock
from detection.yolo_detector import YoloDetector
from detection.opencv_detector import OpenCVCascadeDetector

class CameraManager:
    def __init__(self):
        self.cap = None
        self.is_running = False
        self.lock = Lock()
        self.camera_index = -1

        print("ğŸ¤– ê°ì²´ íƒì§€ ëª¨ë¸ë“¤ì„ ë¡œë”©í•©ë‹ˆë‹¤...")
        self.yolo = YoloDetector(model_path='models/best.pt') 
        # OpenCVë„ ê°™ì€ YOLO ëª¨ë¸ì„ ì‚¬ìš©
        self.opencv = OpenCVCascadeDetector(cascade_dir='models/haarcascades', yolo_model_path='models/best.pt')
        print("âœ… ëª¨ë“  ëª¨ë¸ ë¡œë”© ì™„ë£Œ!")

        # YOLO ëª¨ë¸ í´ë˜ìŠ¤ ì •ë³´ ì¶œë ¥
        if self.yolo.model:
            print(f"ğŸ“‹ YOLO ëª¨ë¸ í´ë˜ìŠ¤ ëª©ë¡:")
            for i, name in self.yolo.model.names.items():
                print(f"   Class_{i}: {name}")
            
            # ë§Œì•½ í´ë˜ìŠ¤ ì´ë¦„ì´ ìˆ«ìë¡œë§Œ ë˜ì–´ ìˆë‹¤ë©´, ì‚¬ìš©ìê°€ ì§ì ‘ ì„¤ì •í•  ìˆ˜ ìˆìŒ
            if len(self.yolo.model.names) > 0:
                first_class = list(self.yolo.model.names.values())[0]
                if first_class.isdigit() or first_class.startswith('Class_'):
                    print("âš ï¸ í´ë˜ìŠ¤ ì´ë¦„ì´ ìˆ«ìë¡œ ë˜ì–´ ìˆìŠµë‹ˆë‹¤. data.yaml íŒŒì¼ì´ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
                    print("ğŸ’¡ í›ˆë ¨ í´ë”ì—ì„œ data.yaml íŒŒì¼ì„ models/ í´ë”ë¡œ ë³µì‚¬í•´ì£¼ì„¸ìš”.")
        else:
            print("âš ï¸ YOLO ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

        # === [ì°¨ì´ì  1] ëª¨ë“  ì„¤ì •ì„ __init__ì—ì„œ ì¤‘ì•™ ê´€ë¦¬í•©ë‹ˆë‹¤ ===
        # ì´ë ‡ê²Œ í•˜ë©´ ì½”ë“œê°€ ë” ê¹”ë”í•´ì§€ê³ , ë‚˜ì¤‘ì— ì„¤ì •ì„ ë°”ê¿€ ë•Œ ì´ ë¶€ë¶„ë§Œ ìˆ˜ì •í•˜ë©´ ë©ë‹ˆë‹¤.
        
        # 1. ê°ì²´ íƒì§€ ëª¨ë¸ í™œì„±í™” ì„¤ì •
        self.yolo_enabled = True
        self.opencv_enabled = True
        print("   -> ğŸ’¡ YOLOì™€ OpenCV ë™ì‹œ íƒì§€ ëª¨ë“œê°€ í™œì„±í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
        
        # 2. í”Œë«í¼ë³„ ìë™ ìµœì í™” ì„¤ì •
        # 64ë¹„íŠ¸ ë¼ì¦ˆë² ë¦¬íŒŒì´(aarch64)ë„ ì •í™•í•˜ê²Œ ê°ì§€í•˜ë„ë¡ ë¡œì§ì„ ê°œì„ í–ˆìŠµë‹ˆë‹¤.
        machine_type = platform.machine().lower()
        self.is_raspberry_pi = 'arm' in machine_type or 'aarch64' in machine_type

        if self.is_raspberry_pi:
            # ğŸ“ ë¼ì¦ˆë² ë¦¬íŒŒì´ í™˜ê²½: ì„±ëŠ¥ ìµœì í™” ëª¨ë“œ
            self.target_width, self.target_height, self.target_fps = 640, 480, 15
            self.detection_interval = 3  # 3í”„ë ˆì„ë§ˆë‹¤ í•œ ë²ˆì”©ë§Œ íƒì§€í•˜ì—¬ CPU ë¶€í•˜ë¥¼ ì¤„ì…ë‹ˆë‹¤.
            print(f"   -> ğŸ“ ë¼ì¦ˆë² ë¦¬íŒŒì´ í™˜ê²½ ê°ì§€! ì„±ëŠ¥ ìµœì í™” ëª¨ë“œë¡œ ì„¤ì •í•©ë‹ˆë‹¤.")
        else:
            # ğŸ’» ë…¸íŠ¸ë¶/ë°ìŠ¤í¬íƒ‘ í™˜ê²½: ê³ í’ˆì§ˆ ëª¨ë“œ
            self.target_width, self.target_height, self.target_fps = 1280, 720, 30
            self.detection_interval = 1  # ë§¤ í”„ë ˆì„ë§ˆë‹¤ íƒì§€í•˜ì—¬ ì‹¤ì‹œê°„ ì •í™•ë„ë¥¼ ë†’ì…ë‹ˆë‹¤.
            print(f"   -> ğŸ’» ë…¸íŠ¸ë¶/PC í™˜ê²½ ê°ì§€! ê³ í’ˆì§ˆ ëª¨ë“œë¡œ ì„¤ì •í•©ë‹ˆë‹¤.")
            
        print(f"   -> ğŸ“Š ìµœì¢… ì„¤ì •: {self.target_width}x{self.target_height} @ {self.target_fps}fps, ê²€ì¶œê°„ê²©: {self.detection_interval}í”„ë ˆì„")
        
        # 3. í”„ë ˆì„ ì¹´ìš´í„° ì´ˆê¸°í™” (ê²€ì¶œ ë¹ˆë„ ì œì–´ìš©)
        self.frame_count = 0
        
        # 4. ê²€ì¶œ ê²°ê³¼ ì €ì¥ ë° ìœ ì§€ ì‹œê°„ ì„¤ì •
        self.detection_results = {
            'yolo': {'boxes': [], 'timestamp': 0},
            'opencv': {'boxes': [], 'timestamp': 0}
        }
        self.result_keep_time = 5.0  # ê²€ì¶œ ê²°ê³¼ë¥¼ 5ì´ˆê°„ ìœ ì§€

    def start_camera(self, index=0):
        with self.lock:
            print(f"ğŸ“· ì¹´ë©”ë¼ (ì¸ë±ìŠ¤ {index}) ì‹œì‘ì„ ì‹œë„í•©ë‹ˆë‹¤...")
            
            if self.cap is not None:
                self.is_running = False
                self.cap.release()
                self.cap = None
                time.sleep(1)

            self.camera_index = index
            
            if platform.system().lower() == "windows":
                # Windowsì—ì„œëŠ” DirectShow ì‚¬ìš©
                self.cap = cv2.VideoCapture(index, cv2.CAP_DSHOW)
            else:
                # Linux/ë¼ì¦ˆë² ë¦¬íŒŒì´ì—ì„œëŠ” ê¸°ë³¸ ë°±ì—”ë“œ ì‚¬ìš©
                self.cap = cv2.VideoCapture(index)
            
            if not self.cap or not self.cap.isOpened():
                print(f"âŒ ì—ëŸ¬: ì¹´ë©”ë¼ {index}ë¥¼ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                self.is_running = False
                return False
            
            # === [ì°¨ì´ì  2] __init__ì—ì„œ ë¯¸ë¦¬ ì •í•´ë‘” ì„¤ì •ê°’ì„ ê°€ì ¸ì™€ ì‚¬ìš©í•©ë‹ˆë‹¤ ===
            # start_camera í•¨ìˆ˜ëŠ” ì´ì œ ì¹´ë©”ë¼ë¥¼ 'ì¼œëŠ”' ì—­í• ì—ë§Œ ì§‘ì¤‘í•©ë‹ˆë‹¤.
            self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, self.target_width)
            self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, self.target_height)
            self.cap.set(cv2.CAP_PROP_FPS, self.target_fps)
            print(f"   -> ì¹´ë©”ë¼ì— ì„¤ì • ì ìš© ì™„ë£Œ.")
            
            self.is_running = True
            print(f"âœ… ì¹´ë©”ë¼ {index}ê°€ ì„±ê³µì ìœ¼ë¡œ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤.")
            return True

    def stop_camera(self):
        with self.lock:
            if self.cap:
                self.is_running = False
                self.cap.release()
                self.cap = None
                print("ğŸ”Œ ì¹´ë©”ë¼ê°€ ì •ì§€ë˜ì—ˆìŠµë‹ˆë‹¤.")

    def put_text_safe(self, img, text, position, font_scale=0.5, color=(255, 255, 255), thickness=1):
        try:
            font = cv2.FONT_HERSHEY_SIMPLEX
            
            # í…ìŠ¤íŠ¸ í¬ê¸° ê³„ì‚°
            (text_width, text_height), baseline = cv2.getTextSize(text, font, font_scale, thickness)
            bg_rect_pt1 = (position[0], position[1] - text_height - baseline)
            bg_rect_pt2 = (position[0] + text_width, position[1] + baseline)
            cv2.rectangle(img, bg_rect_pt1, bg_rect_pt2, (0,0,0), -1) # ê²€ì€ìƒ‰ ë°°ê²½
            cv2.putText(img, text, position, font, font_scale, color, thickness, cv2.LINE_AA)
        except Exception as e:
            print(f"í…ìŠ¤íŠ¸ ë Œë”ë§ ì˜¤ë¥˜: {e}")

    def generate_frames(self):
        # === [ì°¨ì´ì  3] __init__ì—ì„œ ë¯¸ë¦¬ ì •í•´ë‘” FPS ê°’ì„ ê°€ì ¸ì™€ ì‚¬ìš©í•©ë‹ˆë‹¤ ===
        frame_time = 1.0 / self.target_fps
        last_frame_time = time.time()
        
        while True:
            current_time = time.time()
            
            # FPS ì œí•œ ì ìš©
            if current_time - last_frame_time < frame_time:
                time.sleep(0.005) # CPU ì‚¬ìš©ëŸ‰ì„ ì¤„ì´ê¸° ìœ„í•´ ì§§ê²Œ ëŒ€ê¸°
                continue
            
            last_frame_time = current_time

            frame = None
            with self.lock:
                if not self.is_running or self.cap is None:
                    time.sleep(0.1)
                    continue
                ret, frame = self.cap.read()

            if frame is None: continue

            try:
                # === [ì„ì´ë‹˜ ì•„ì´ë””ì–´] í”„ë ˆì„ë³„ ê²€ì¶œ ë¹ˆë„ ì œì–´ ===
                self.frame_count += 1
                should_detect = (self.frame_count % self.detection_interval == 0)
                current_time = time.time()
                
                # ë””ë²„ê·¸: 5ì´ˆë§ˆë‹¤ ê²€ì¶œ ìƒíƒœ ì¶œë ¥
                if hasattr(self, '_last_debug_time'):
                    if current_time - self._last_debug_time > 5:
                        yolo_count = len(self.detection_results['yolo']['boxes'])
                        opencv_count = len(self.detection_results['opencv']['boxes'])
                        print(f"ğŸ” ê²€ì¶œ ìƒíƒœ - YOLO: {yolo_count}ê°œ, OpenCV: {opencv_count}ê°œ")
                        self._last_debug_time = current_time
                else:
                    self._last_debug_time = current_time
                
                # ìƒˆë¡œìš´ ê²€ì¶œ ìˆ˜í–‰ (3í”„ë ˆì„ë§ˆë‹¤)
                if should_detect:
                    # 1. YOLO íƒì§€ (íŒŒë€ìƒ‰)
                    if self.yolo_enabled and self.yolo.model:
                        results = self.yolo.detect(frame)
                        if results:
                            yolo_boxes = []
                            for r in results:
                                for box in r.boxes:
                                    x1, y1, x2, y2 = map(int, box.xyxy[0])
                                    conf = float(box.conf[0])
                                    cls_id = int(box.cls[0])
                                    class_name = self.yolo.model.names.get(cls_id, f"Class_{cls_id}")
                                    # í•œê¸€ í´ë˜ìŠ¤ëª… ì²˜ë¦¬
                                    if isinstance(class_name, str) and not class_name.isascii():
                                        class_name = f"Class_{cls_id}"
                                    
                                    # ë””ë²„ê·¸: í´ë˜ìŠ¤ IDì™€ ì´ë¦„ ì¶œë ¥
                                    print(f"ğŸ¦Œ YOLO ê²€ì¶œ - ID: {cls_id}, ì´ë¦„: {class_name}, ì‹ ë¢°ë„: {conf:.2f}")
                                    
                                    yolo_boxes.append({
                                        'coords': (x1, y1, x2, y2),
                                        'conf': conf,
                                        'class_name': class_name
                                    })
                            # ê²€ì¶œ ê²°ê³¼ ì €ì¥
                            self.detection_results['yolo'] = {
                                'boxes': yolo_boxes,
                                'timestamp': current_time
                            }

                    # 2. OpenCV íƒì§€ (ë¹¨ê°„ìƒ‰)
                    if self.opencv_enabled and self.opencv.yolo_model:
                        opencv_results = self.opencv.detect_yolo_objects(frame)
                        if opencv_results:
                            opencv_boxes = []
                            for r in opencv_results:
                                for box in r.boxes:
                                    x1, y1, x2, y2 = map(int, box.xyxy[0])
                                    conf = float(box.conf[0])
                                    cls_id = int(box.cls[0])
                                    class_name = self.opencv.yolo_model.names.get(cls_id, f"Class_{cls_id}")
                                    # í•œê¸€ í´ë˜ìŠ¤ëª… ì²˜ë¦¬
                                    if isinstance(class_name, str) and not class_name.isascii():
                                        class_name = f"Class_{cls_id}"
                                    
                                    # ë””ë²„ê·¸: í´ë˜ìŠ¤ IDì™€ ì´ë¦„ ì¶œë ¥
                                    print(f"ğŸ”´ OpenCV ê²€ì¶œ - ID: {cls_id}, ì´ë¦„: {class_name}, ì‹ ë¢°ë„: {conf:.2f}")
                                    
                                    opencv_boxes.append({
                                        'coords': (x1, y1, x2, y2),
                                        'conf': conf,
                                        'class_name': class_name
                                    })
                            # ê²€ì¶œ ê²°ê³¼ ì €ì¥
                            self.detection_results['opencv'] = {
                                'boxes': opencv_boxes,
                                'timestamp': current_time
                            }
                
                # === ê²€ì¶œ ê²°ê³¼ ê·¸ë¦¬ê¸° (5ì´ˆê°„ ìœ ì§€) ===
                # YOLO ê²°ê³¼ ê·¸ë¦¬ê¸°
                yolo_time_diff = current_time - self.detection_results['yolo']['timestamp']
                if yolo_time_diff < self.result_keep_time:
                    for box_info in self.detection_results['yolo']['boxes']:
                        x1, y1, x2, y2 = box_info['coords']
                        color = (255, 191, 0)  # íŒŒë€ìƒ‰ (BGR)
                        cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)
                        label = f'YOLO: {box_info["class_name"]} {box_info["conf"]:.2f}'
                        self.put_text_safe(frame, label, (x1, y1 - 10), color=color)
                
                # OpenCV ê²°ê³¼ ê·¸ë¦¬ê¸°
                opencv_time_diff = current_time - self.detection_results['opencv']['timestamp']
                if opencv_time_diff < self.result_keep_time:
                    for box_info in self.detection_results['opencv']['boxes']:
                        x1, y1, x2, y2 = box_info['coords']
                        color = (0, 0, 255)  # ë¹¨ê°„ìƒ‰ (BGR)
                        cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)
                        label = f'OpenCV: {box_info["class_name"]} {box_info["conf"]:.2f}'
                        self.put_text_safe(frame, label, (x1, y2 + 20), color=color)

            except Exception as e:
                print(f"íƒì§€/ê·¸ë¦¬ê¸° ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

            (flag, encodedImage) = cv2.imencode(".jpg", frame)
            if not flag: continue
            yield(b'--frame\r\n' b'Content-Type: image/jpeg\r\n\r\n' + 
                  bytearray(encodedImage) + b'\r\n')

# ì „ì—­ ì¹´ë©”ë¼ ë§¤ë‹ˆì € ì¸ìŠ¤í„´ìŠ¤
camera_manager = CameraManager()