# /home/pi/autocarz/src/8_web_streamer.py
from flask import Flask, Response, render_template_string, request, jsonify
from PIL import Image, ImageDraw, ImageFont
from picamera2 import Picamera2
import cv2
import time
import threading
from queue import Queue
import numpy as np
import json
import os

app = Flask(__name__)

# ì „ì—­ ë³€ìˆ˜
model = None
yolo_available = False
opencv_cascades = {}

# ë°˜ì „ ì„¤ì • íŒŒì¼ ê²½ë¡œ
SETTINGS_FILE = "/home/pi/autocarz/camera_settings.json"

# ê¸°ë³¸ ë°˜ì „ ì„¤ì •
flip_settings = {
    "horizontal": False,  # ì¢Œìš° ë°˜ì „
    "vertical": False,    # ìƒí•˜ ë°˜ì „
    "rotation": 0         # íšŒì „ (0, 90, 180, 270)
}

# ê²€ì¶œ ëª¨ë“œ ì„¤ì •
detection_settings = {
    "yolo_enabled": True,      # YOLO ê²€ì¶œ í™œì„±í™” (íŒŒë€ìƒ‰)
    "opencv_enabled": True,    # OpenCV ê²€ì¶œ í™œì„±í™” (ë¹¨ê°„ìƒ‰)
    "show_fps": True          # FPS í‘œì‹œ
}

def load_settings():
    """ì„¤ì • íŒŒì¼ì—ì„œ ë°˜ì „ ì„¤ì • ë¡œë“œ"""
    global flip_settings, detection_settings
    try:
        if os.path.exists(SETTINGS_FILE):
            with open(SETTINGS_FILE, 'r') as f:
                loaded_settings = json.load(f)
                # ê¸°ì¡´ flip_settings í˜¸í™˜ì„± ìœ ì§€
                if 'flip_settings' in loaded_settings:
                    flip_settings.update(loaded_settings['flip_settings'])
                else:
                    flip_settings.update(loaded_settings)
                
                # detection_settings ë¡œë“œ
                if 'detection_settings' in loaded_settings:
                    detection_settings.update(loaded_settings['detection_settings'])
                
                print(f"ì„¤ì • ë¡œë“œ ì™„ë£Œ: {flip_settings}")
    except Exception as e:
        print(f"ì„¤ì • ë¡œë“œ ì—ëŸ¬: {e}")

def save_settings():
    """ì„¤ì •ì„ íŒŒì¼ì— ì €ì¥"""
    try:
        os.makedirs(os.path.dirname(SETTINGS_FILE), exist_ok=True)
        # ê¸°ì¡´ í˜¸í™˜ì„± ìœ ì§€ë¥¼ ìœ„í•´ flip_settingsë¥¼ ìµœìƒìœ„ì— ì €ì¥
        settings_data = flip_settings.copy()
        settings_data['detection_settings'] = detection_settings
        
        with open(SETTINGS_FILE, 'w') as f:
            json.dump(settings_data, f, indent=2)
        print(f"ì„¤ì • ì €ì¥ ì™„ë£Œ: {settings_data}")
    except Exception as e:
        print(f"ì„¤ì • ì €ì¥ ì—ëŸ¬: {e}")

def apply_flip_transform(frame):
    """í”„ë ˆì„ì— ë°˜ì „ ë° íšŒì „ ì ìš©"""
    try:
        # ì¢Œìš° ë°˜ì „ (ìˆ˜í‰)
        if flip_settings["horizontal"]:
            frame = cv2.flip(frame, 1)
        
        # ìƒí•˜ ë°˜ì „ (ìˆ˜ì§)
        if flip_settings["vertical"]:
            frame = cv2.flip(frame, 0)
        
        # íšŒì „ ì ìš©
        rotation = flip_settings["rotation"]
        if rotation == 90:
            frame = cv2.rotate(frame, cv2.ROTATE_90_CLOCKWISE)
        elif rotation == 180:
            frame = cv2.rotate(frame, cv2.ROTATE_180)
        elif rotation == 270:
            frame = cv2.rotate(frame, cv2.ROTATE_90_COUNTERCLOCKWISE)
        
        return frame
    except Exception as e:
        print(f"ë°˜ì „ ì ìš© ì—ëŸ¬: {e}")
        return frame

def initialize_opencv_cascades():
    """OpenCV Haar Cascade ì´ˆê¸°í™”"""
    global opencv_cascades
    
    try:
        # ì–¼êµ´ ê²€ì¶œ ìºìŠ¤ì¼€ì´ë“œ
        face_cascade_path = cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'
        if os.path.exists(face_cascade_path):
            opencv_cascades['face'] = cv2.CascadeClassifier(face_cascade_path)
            print("OpenCV ì–¼êµ´ ê²€ì¶œ ìºìŠ¤ì¼€ì´ë“œ ë¡œë“œ ì™„ë£Œ")
        
        # ëˆˆ ê²€ì¶œ ìºìŠ¤ì¼€ì´ë“œ
        eye_cascade_path = cv2.data.haarcascades + 'haarcascade_eye.xml'
        if os.path.exists(eye_cascade_path):
            opencv_cascades['eye'] = cv2.CascadeClassifier(eye_cascade_path)
            print("OpenCV ëˆˆ ê²€ì¶œ ìºìŠ¤ì¼€ì´ë“œ ë¡œë“œ ì™„ë£Œ")
        
        print(f"OpenCV ìºìŠ¤ì¼€ì´ë“œ ë¡œë“œ ì™„ë£Œ: {list(opencv_cascades.keys())}")
        return len(opencv_cascades) > 0
        
    except Exception as e:
        print(f"OpenCV ìºìŠ¤ì¼€ì´ë“œ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return False

def opencv_detect_objects(frame_bgr):
    """OpenCVë¡œ ê°ì²´ ê²€ì¶œ (ë¹¨ê°„ìƒ‰ ë°•ìŠ¤ë¡œ í‘œì‹œí•  ì˜ˆì •)"""
    detections = []
    
    try:
        # BGR to Gray ë³€í™˜
        gray = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2GRAY)
        
        # ê° ìºìŠ¤ì¼€ì´ë“œë¡œ ê²€ì¶œ
        for cascade_name, cascade in opencv_cascades.items():
            try:
                objects = cascade.detectMultiScale(
                    gray,
                    scaleFactor=1.1,
                    minNeighbors=5,
                    minSize=(30, 30)
                )
                
                for (x, y, w, h) in objects:
                    detections.append({
                        'bbox': (x, y, x+w, y+h),
                        'class': cascade_name,
                        'confidence': 0.95  # OpenCVëŠ” ì‹ ë¢°ë„ë¥¼ ì œê³µí•˜ì§€ ì•Šìœ¼ë¯€ë¡œ ê³ ì •ê°’
                    })
                    
            except Exception as e:
                print(f"OpenCV {cascade_name} ê²€ì¶œ ì—ëŸ¬: {e}")
                
    except Exception as e:
        print(f"OpenCV ê²€ì¶œ ì—ëŸ¬: {e}")
    
    return detections

def draw_yolo_boxes(frame, results):
    """YOLO ê²€ì¶œ ê²°ê³¼ë¥¼ íŒŒë€ìƒ‰ ë°•ìŠ¤ë¡œ ê·¸ë¦¬ê¸°"""
    try:
        if not results or len(results) == 0:
            return frame
            
        result = results[0]
        
        # ë°•ìŠ¤ ì •ë³´ê°€ ìˆëŠ”ì§€ í™•ì¸
        if result.boxes is None or len(result.boxes) == 0:
            return frame
        
        # ê° ë°•ìŠ¤ì— ëŒ€í•´ ì²˜ë¦¬
        for box in result.boxes:
            try:
                # ë°•ìŠ¤ ì¢Œí‘œ (xyxy í˜•ì‹)
                x1, y1, x2, y2 = box.xyxy[0].cpu().numpy().astype(int)
                
                # ì‹ ë¢°ë„
                conf = float(box.conf[0].cpu().numpy())
                
                # í´ë˜ìŠ¤ ID
                cls_id = int(box.cls[0].cpu().numpy())
                
                # í´ë˜ìŠ¤ ì´ë¦„ (í•œê¸€ ì²˜ë¦¬)
                class_names = result.names
                if cls_id in class_names:
                    class_name = class_names[cls_id]
                else:
                    class_name = f"Class_{cls_id}"
                
                # YOLO ë°•ìŠ¤ ê·¸ë¦¬ê¸° (íŒŒë€ìƒ‰)
                cv2.rectangle(frame, (x1, y1), (x2, y2), (255, 0, 0), 2)  # BGRì—ì„œ íŒŒë€ìƒ‰
                
                # ë ˆì´ë¸” í…ìŠ¤íŠ¸ (ì˜ì–´ë§Œ ì‚¬ìš©í•˜ì—¬ ì¸ì½”ë”© ë¬¸ì œ ë°©ì§€)
                if isinstance(class_name, str):
                    try:
                        class_name.encode('ascii')
                        label = f"YOLO-{class_name}: {conf:.2f}"
                    except UnicodeEncodeError:
                        label = f"YOLO-Obj{cls_id}: {conf:.2f}"
                else:
                    label = f"YOLO-Obj{cls_id}: {conf:.2f}"
                
                # í…ìŠ¤íŠ¸ ë°°ê²½ ë°•ìŠ¤ í¬ê¸° ê³„ì‚°
                (text_width, text_height), baseline = cv2.getTextSize(
                    label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 2
                )
                
                # í…ìŠ¤íŠ¸ ë°°ê²½ ë°•ìŠ¤ ê·¸ë¦¬ê¸° (íŒŒë€ìƒ‰)
                cv2.rectangle(
                    frame,
                    (x1, y1 - text_height - baseline - 5),
                    (x1 + text_width, y1),
                    (255, 0, 0),  # BGRì—ì„œ íŒŒë€ìƒ‰
                    -1
                )
                
                # í…ìŠ¤íŠ¸ ê·¸ë¦¬ê¸° (í°ìƒ‰)
                cv2.putText(
                    frame,
                    label,
                    (x1, y1 - baseline - 2),
                    cv2.FONT_HERSHEY_SIMPLEX,
                    0.5,
                    (255, 255, 255),  # í°ìƒ‰
                    2
                )
                
            except Exception as box_error:
                print(f"YOLO ë°•ìŠ¤ ê·¸ë¦¬ê¸° ì—ëŸ¬: {box_error}")
                continue
        
        return frame
        
    except Exception as e:
        print(f"YOLO ë°•ìŠ¤ ê·¸ë¦¬ê¸° ì—ëŸ¬: {e}")
        return frame

def draw_opencv_boxes(frame, detections):
    """OpenCV ê²€ì¶œ ê²°ê³¼ë¥¼ ë¹¨ê°„ìƒ‰ ë°•ìŠ¤ë¡œ ê·¸ë¦¬ê¸°"""
    try:
        for detection in detections:
            x1, y1, x2, y2 = detection['bbox']
            class_name = detection['class']
            confidence = detection['confidence']
            
            # OpenCV ë°•ìŠ¤ ê·¸ë¦¬ê¸° (ë¹¨ê°„ìƒ‰)
            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 0, 255), 2)  # BGRì—ì„œ ë¹¨ê°„ìƒ‰
            
            # ë ˆì´ë¸” í…ìŠ¤íŠ¸
            label = f"CV-{class_name}: {confidence:.2f}"
            
            # í…ìŠ¤íŠ¸ ë°°ê²½ ë°•ìŠ¤ í¬ê¸° ê³„ì‚°
            (text_width, text_height), baseline = cv2.getTextSize(
                label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 2
            )
            
            # í…ìŠ¤íŠ¸ ë°°ê²½ ë°•ìŠ¤ ê·¸ë¦¬ê¸° (ë¹¨ê°„ìƒ‰)
            cv2.rectangle(
                frame,
                (x1, y1 - text_height - baseline - 5),
                (x1 + text_width, y1),
                (0, 0, 255),  # BGRì—ì„œ ë¹¨ê°„ìƒ‰
                -1
            )
            
            # í…ìŠ¤íŠ¸ ê·¸ë¦¬ê¸° (í°ìƒ‰)
            cv2.putText(
                frame,
                label,
                (x1, y1 - baseline - 2),
                cv2.FONT_HERSHEY_SIMPLEX,
                0.5,
                (255, 255, 255),  # í°ìƒ‰
                2
            )
    
    except Exception as e:
        print(f"OpenCV ë°•ìŠ¤ ê·¸ë¦¬ê¸° ì—ëŸ¬: {e}")
    
    return frame

def check_numpy_compatibility():
    """numpy í˜¸í™˜ì„± í™•ì¸"""
    try:
        import numpy as np
        print(f"NumPy ë²„ì „: {np.__version__}")
        
        # ê¸°ë³¸ í…ŒìŠ¤íŠ¸
        test_array = np.zeros((100, 100, 3), dtype=np.uint8)
        test_array = np.ascontiguousarray(test_array)
        
        print("NumPy ê¸°ë³¸ í…ŒìŠ¤íŠ¸ í†µê³¼")
        return True
        
    except Exception as e:
        print(f"NumPy í˜¸í™˜ì„± ë¬¸ì œ: {e}")
        return False

def initialize_yolo_model():
    """YOLO ëª¨ë¸ ì´ˆê¸°í™” - numpy í˜¸í™˜ì„± ë¬¸ì œ í•´ê²°"""
    global model, yolo_available
    
    try:
        from ultralytics import YOLO
        import numpy as np
        
        # ëª¨ë¸ ê²½ë¡œ í™•ì¸
        model_path = "/home/pi/autocarz/models/best.pt"
        if not os.path.exists(model_path):
            print(f"ëª¨ë¸ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {model_path}")
            yolo_available = False
            return
        
        print(f"YOLO ëª¨ë¸ ë¡œë“œ ì‹œë„: {model_path}")
        
        # ëª¨ë¸ ë¡œë“œ
        model = YOLO(model_path)
        
        # ëª¨ë¸ ì„¤ì •
        model.overrides['verbose'] = False
        model.overrides['device'] = 'cpu'
        model.overrides['half'] = False
        
        # í…ŒìŠ¤íŠ¸ ì¶”ë¡  - numpy í˜¸í™˜ì„± ë¬¸ì œ í•´ê²°
        print("í…ŒìŠ¤íŠ¸ ì¶”ë¡  ì‹œì‘...")
        
        # ëª…ì‹œì ìœ¼ë¡œ numpy ë°°ì—´ ìƒì„± (í˜¸í™˜ì„± í™•ë³´)
        test_frame = np.zeros((480, 640, 3), dtype=np.uint8)
        
        # ë©”ëª¨ë¦¬ ì—°ì†ì„± í™•ë³´
        test_frame = np.ascontiguousarray(test_frame)
        
        # ì•ˆì „í•œ ì¶”ë¡  ì‹¤í–‰
        try:
            with np.errstate(all='ignore'):  # numpy ê²½ê³  ë¬´ì‹œ
                test_results = model.predict(
                    test_frame,
                    verbose=False,
                    conf=0.5,
                    device='cpu',
                    half=False,
                    augment=False,
                    agnostic_nms=False
                )
            
            if test_results:
                print("í…ŒìŠ¤íŠ¸ ì¶”ë¡  ì„±ê³µ!")
                yolo_available = True
                print("YOLO ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
                return
            else:
                print("í…ŒìŠ¤íŠ¸ ì¶”ë¡  ê²°ê³¼ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤")
                
        except Exception as inference_error:
            print(f"ì¶”ë¡  í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {inference_error}")
            
            # ëŒ€ì•ˆ: ë” ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸
            try:
                print("ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ ì‹œë„...")
                simple_test = np.ones((320, 320, 3), dtype=np.uint8) * 128
                simple_test = np.ascontiguousarray(simple_test)
                
                test_results = model(simple_test, verbose=False)
                if test_results:
                    print("ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ ì„±ê³µ!")
                    yolo_available = True
                    print("YOLO ëª¨ë¸ ë¡œë“œ ì™„ë£Œ (ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸)")
                    return
                    
            except Exception as simple_error:
                print(f"ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ë„ ì‹¤íŒ¨: {simple_error}")
        
        # ëª¨ë“  í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨
        yolo_available = False
        model = None
        print("YOLO ëª¨ë¸ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨ - ì›ë³¸ ì˜ìƒë§Œ í‘œì‹œë©ë‹ˆë‹¤")
        
    except ImportError as e:
        print(f"ultralytics import ì‹¤íŒ¨: {e}")
        yolo_available = False
    except Exception as e:
        print(f"YOLO ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
        print(f"ì—ëŸ¬ íƒ€ì…: {type(e).__name__}")
        
        # ì¶”ê°€ ë””ë²„ê¹… ì •ë³´
        try:
            import traceback
            print("ìƒì„¸ ì—ëŸ¬ ì •ë³´:")
            traceback.print_exc()
        except:
            pass
            
        yolo_available = False

# ì¹´ë©”ë¼ ì„¤ì •
picam2 = Picamera2()
picam2.preview_configuration.main.size = (640, 480)
picam2.preview_configuration.main.format = "RGB888"
picam2.configure("preview")
picam2.start()
time.sleep(2)

# í”„ë ˆì„ í
frame_queue = Queue(maxsize=2)
processed_queue = Queue(maxsize=2)

# FPS ê³„ì‚°ìš© ë³€ìˆ˜
fps_counter = 0
fps_start_time = time.time()
current_fps = 0

def capture_frames():
    """ì¹´ë©”ë¼ì—ì„œ í”„ë ˆì„ì„ ìº¡ì²˜í•˜ëŠ” ìŠ¤ë ˆë“œ - ê°œì„ ëœ ë²„ì „"""
    while True:
        try:
            # ì¹´ë©”ë¼ì—ì„œ í”„ë ˆì„ ìº¡ì²˜
            frame = picam2.capture_array()
            
            # í”„ë ˆì„ ìœ íš¨ì„± ê²€ì‚¬
            if frame is None:
                print("ìº¡ì²˜ëœ í”„ë ˆì„ì´ Noneì…ë‹ˆë‹¤")
                time.sleep(0.1)
                continue
            
            # numpy ë°°ì—´ í™•ì¸ ë° ë³€í™˜
            if not isinstance(frame, np.ndarray):
                print(f"í”„ë ˆì„ì´ numpy ë°°ì—´ì´ ì•„ë‹™ë‹ˆë‹¤: {type(frame)}")
                frame = np.array(frame)
            
            # ë°ì´í„° íƒ€ì… í™•ì¸
            if frame.dtype != np.uint8:
                if frame.dtype == np.float32 or frame.dtype == np.float64:
                    # 0-1 ë²”ìœ„ë¼ë©´ 0-255ë¡œ ë³€í™˜
                    if frame.max() <= 1.0:
                        frame = (frame * 255).astype(np.uint8)
                    else:
                        frame = frame.astype(np.uint8)
                else:
                    frame = frame.astype(np.uint8)
            
            # í”„ë ˆì„ ì°¨ì› í™•ì¸
            if len(frame.shape) != 3:
                print(f"ì˜ëª»ëœ í”„ë ˆì„ ì°¨ì›: {frame.shape}")
                continue
            
            # RGB ì±„ë„ í™•ì¸
            if frame.shape[2] != 3:
                print(f"RGB ì±„ë„ì´ 3ê°œê°€ ì•„ë‹™ë‹ˆë‹¤: {frame.shape[2]}")
                continue
            
            # ë©”ëª¨ë¦¬ ì—°ì†ì„± í™•ì¸
            if not frame.flags['C_CONTIGUOUS']:
                frame = np.ascontiguousarray(frame)
            
            # ë°˜ì „ ë° íšŒì „ ì ìš©
            frame = apply_flip_transform(frame)
            
            # íì— í”„ë ˆì„ ì¶”ê°€
            if not frame_queue.full():
                frame_queue.put(frame)
            else:
                # íê°€ ê°€ë“ ì°¬ ê²½ìš° ì˜¤ë˜ëœ í”„ë ˆì„ ì œê±°
                try:
                    frame_queue.get_nowait()
                    frame_queue.put(frame)
                except:
                    pass
            
            time.sleep(0.03)
            
        except Exception as e:
            print(f"ì¹´ë©”ë¼ ìº¡ì²˜ ì—ëŸ¬: {e}")
            time.sleep(0.1)

def process_frames():
    """ì´ì¤‘ ê²€ì¶œ ì²˜ë¦¬ (YOLO íŒŒë€ìƒ‰ + OpenCV ë¹¨ê°„ìƒ‰)"""
    global fps_counter, fps_start_time, current_fps
    frame_count = 0
    
    while True:
        if not frame_queue.empty():
            frame = frame_queue.get()
            frame_count += 1
            
            # FPS ê³„ì‚°
            fps_counter += 1
            if time.time() - fps_start_time >= 1.0:
                current_fps = fps_counter
                fps_counter = 0
                fps_start_time = time.time()
            
            try:
                # í”„ë ˆì„ ì „ì²˜ë¦¬ - numpy í˜¸í™˜ì„± í™•ë³´
                if not isinstance(frame, np.ndarray):
                    frame = np.array(frame, dtype=np.uint8)
                
                # ì°¨ì› ë° íƒ€ì… ê²€ì¦
                if len(frame.shape) != 3 or frame.shape[2] != 3:
                    print(f"ì˜ëª»ëœ í”„ë ˆì„ ì°¨ì›: {frame.shape}")
                    if not processed_queue.full():
                        processed_queue.put(frame)
                    continue
                
                # ë°ì´í„° íƒ€ì… ì •ê·œí™”
                if frame.dtype != np.uint8:
                    if frame.dtype in [np.float32, np.float64]:
                        if frame.max() <= 1.0:
                            frame = (frame * 255).astype(np.uint8)
                        else:
                            frame = np.clip(frame, 0, 255).astype(np.uint8)
                    else:
                        frame = frame.astype(np.uint8)
                
                # í”½ì…€ ê°’ ë²”ìœ„ í™•ì¸
                frame = np.clip(frame, 0, 255).astype(np.uint8)
                
                # ë©”ëª¨ë¦¬ ì—°ì†ì„± í™•ë³´
                if not frame.flags['C_CONTIGUOUS']:
                    frame = np.ascontiguousarray(frame)
                
                # RGB to BGR ë³€í™˜
                frame_bgr = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)
                frame_bgr = np.ascontiguousarray(frame_bgr)
                
                # ê²°ê³¼ í”„ë ˆì„ ì´ˆê¸°í™”
                result_frame = frame_bgr.copy()
                
                yolo_count = 0
                opencv_count = 0
                
                # YOLO ê²€ì¶œ (íŒŒë€ìƒ‰ ë°•ìŠ¤)
                if detection_settings["yolo_enabled"] and yolo_available and model is not None:
                    try:
                        with np.errstate(all='ignore'):
                            results = model.predict(
                                frame_bgr,
                                verbose=False,
                                conf=0.5,
                                device='cpu',
                                half=False,
                                augment=False,
                                agnostic_nms=False,
                                max_det=100
                            )
                        
                        if results and len(results) > 0:
                            result_frame = draw_yolo_boxes(result_frame, results)
                            if results[0].boxes is not None:
                                yolo_count = len(results[0].boxes)
                            
                    except Exception as yolo_error:
                        if frame_count % 100 == 0:  # ë„ˆë¬´ ë§ì€ ë¡œê·¸ ë°©ì§€
                            print(f"YOLO ì¶”ë¡  ì—ëŸ¬: {yolo_error}")
                
                # OpenCV ê²€ì¶œ (ë¹¨ê°„ìƒ‰ ë°•ìŠ¤)
                if detection_settings["opencv_enabled"] and len(opencv_cascades) > 0:
                    try:
                        opencv_detections = opencv_detect_objects(result_frame)
                        opencv_count = len(opencv_detections)
                        
                        if opencv_detections:
                            result_frame = draw_opencv_boxes(result_frame, opencv_detections)
                            
                    except Exception as opencv_error:
                        if frame_count % 100 == 0:
                            print(f"OpenCV ê²€ì¶œ ì—ëŸ¬: {opencv_error}")
                
                # FPS ë° ê²€ì¶œ ì •ë³´ í‘œì‹œ
                if detection_settings["show_fps"]:
                    # FPS í‘œì‹œ
                    cv2.putText(result_frame, f"FPS: {current_fps}", (10, 30), 
                              cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
                    
                    # ê²€ì¶œ ê°œìˆ˜ í‘œì‹œ
                    info_text = f"YOLO(Blue): {yolo_count} | OpenCV(Red): {opencv_count}"
                    cv2.putText(result_frame, info_text, (10, 60), 
                              cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)
                
                # BGR to RGB ë³€í™˜
                result_frame = cv2.cvtColor(result_frame, cv2.COLOR_BGR2RGB)
                result_frame = np.ascontiguousarray(result_frame)
                
                # íì— ê²°ê³¼ ì¶”ê°€
                if not processed_queue.full():
                    processed_queue.put(result_frame)
                else:
                    # íê°€ ê°€ë“ ì°¬ ê²½ìš° ì˜¤ë˜ëœ í”„ë ˆì„ ì œê±°
                    try:
                        processed_queue.get_nowait()
                        processed_queue.put(result_frame)
                    except:
                        pass
                        
            except Exception as e:
                if frame_count % 100 == 0:  # ë„ˆë¬´ ë§ì€ ë¡œê·¸ ë°©ì§€
                    print(f"í”„ë ˆì„ ì²˜ë¦¬ ì—ëŸ¬: {e}")
                
                # ì—ëŸ¬ ì‹œ ì›ë³¸ í”„ë ˆì„ ì‚¬ìš©
                if not processed_queue.full():
                    processed_queue.put(frame)
        
        time.sleep(0.01)

def generate_frames():
    """ì›¹ ìŠ¤íŠ¸ë¦¬ë°ìš© í”„ë ˆì„ ìƒì„±"""
    while True:
        if not processed_queue.empty():
            annotated_frame = processed_queue.get()
            
            try:
                # RGB to BGR ë³€í™˜ (JPEG ì¸ì½”ë”©ìš©)
                frame_bgr = cv2.cvtColor(annotated_frame, cv2.COLOR_RGB2BGR)
                
                # JPEG ì••ì¶•
                encode_param = [cv2.IMWRITE_JPEG_QUALITY, 75]
                success, buffer = cv2.imencode(".jpg", frame_bgr, encode_param)
                
                if success:
                    frame_bytes = buffer.tobytes()
                    yield (b"--frame\r\n"
                           b"Content-Type: image/jpeg\r\n\r\n" + frame_bytes + b"\r\n")
            except Exception as e:
                print(f"í”„ë ˆì„ ì¸ì½”ë”© ì—ëŸ¬: {e}")
        else:
            time.sleep(0.01)

@app.route("/")
def index():
    yolo_status = "í™œì„±í™”ë¨" if yolo_available else "ë¹„í™œì„±í™”ë¨"
    opencv_status = "í™œì„±í™”ë¨" if len(opencv_cascades) > 0 else "ë¹„í™œì„±í™”ë¨"
    
    html_template = """
    <!DOCTYPE html>
    <html>
    <head>
        <title>YOLO + OpenCV ì´ì¤‘ ê²€ì¶œ ìŠ¤íŠ¸ë¦¬ë°</title>
        <meta charset="UTF-8">
        <style>
            body { font-family: Arial, sans-serif; margin: 20px; }
            .container { max-width: 1200px; margin: 0 auto; }
            .video-container { text-align: center; margin: 20px 0; }
            .controls { background: #f5f5f5; padding: 20px; border-radius: 8px; margin: 20px 0; }
            .control-group { margin: 10px 0; }
            .control-group label { display: inline-block; width: 150px; }
            button { padding: 8px 16px; margin: 5px; border: none; border-radius: 4px; cursor: pointer; }
            .btn-primary { background: #007bff; color: white; }
            .btn-success { background: #28a745; color: white; }
            .btn-warning { background: #ffc107; color: black; }
            .btn-danger { background: #dc3545; color: white; }
            .status { padding: 10px; margin: 10px 0; border-radius: 4px; }
            .status.success { background: #d4edda; border: 1px solid #c3e6cb; }
            .status.error { background: #f8d7da; border: 1px solid #f5c6cb; }
            .status.info { background: #d1ecf1; border: 1px solid #bee5eb; }
            input[type="checkbox"] { margin-right: 8px; }
            select { padding: 5px; margin-left: 10px; }
            .legend { background: #e9ecef; padding: 15px; border-radius: 8px; margin: 20px 0; }
            .legend-item { display: inline-block; margin: 5px 15px; }
            .color-box { display: inline-block; width: 20px; height: 20px; margin-right: 5px; vertical-align: middle; border: 1px solid #000; }
            .blue-box { background-color: blue; }
            .red-box { background-color: red; }
        </style>
    </head>
    <body>
        <div class="container">
            <h1>ğŸ” YOLO + OpenCV ì´ì¤‘ ê²€ì¶œ ìŠ¤íŠ¸ë¦¬ë°</h1>
            
            <div class="status info">
                <p><strong>YOLO ìƒíƒœ:</strong> {{ yolo_status }}</p>
                <p><strong>OpenCV ìƒíƒœ:</strong> {{ opencv_status }}</p>
                <p><strong>ì¹´ë©”ë¼:</strong> Pi Camera v2 (640x480)</p>
                <p><strong>ì„±ëŠ¥ ë¹„êµ:</strong> ì‹¤ì‹œê°„ ì´ì¤‘ ê²€ì¶œ + ë”œë ˆì´ ì¸¡ì •</p>
            </div>
            
            <div class="legend">
                <h3>ğŸ¨ ê²€ì¶œ ê²°ê³¼ ìƒ‰ìƒ êµ¬ë¶„</h3>
                <div class="legend-item">
                    <span class="color-box blue-box"></span>
                    <strong>íŒŒë€ìƒ‰ ë°•ìŠ¤:</strong> YOLO v8 ê²€ì¶œ ê²°ê³¼
                </div>
                <div class="legend-item">
                    <span class="color-box red-box"></span>
                    <strong>ë¹¨ê°„ìƒ‰ ë°•ìŠ¤:</strong> OpenCV Haar Cascade ê²€ì¶œ ê²°ê³¼
                </div>
            </div>
            
            <div class="controls">
                <h3>ğŸ›ï¸ ê²€ì¶œ ì„¤ì •</h3>
                
                <div class="control-group">
                    <label>
                        <input type="checkbox" id="yolo_enabled" {{ 'checked' if detection_settings.yolo_enabled else '' }}>
                        YOLO ê²€ì¶œ í™œì„±í™” (íŒŒë€ìƒ‰)
                    </label>
                </div>
                
                <div class="control-group">
                    <label>
                        <input type="checkbox" id="opencv_enabled" {{ 'checked' if detection_settings.opencv_enabled else '' }}>
                        OpenCV ê²€ì¶œ í™œì„±í™” (ë¹¨ê°„ìƒ‰)
                    </label>
                </div>
                
                <div class="control-group">
                    <label>
                        <input type="checkbox" id="show_fps" {{ 'checked' if detection_settings.show_fps else '' }}>
                        FPS ë° ê²€ì¶œ ì •ë³´ í‘œì‹œ
                    </label>
                </div>
                
                <button class="btn-primary" onclick="applyDetectionSettings()">ê²€ì¶œ ì„¤ì • ì ìš©</button>
            </div>
            
            <div class="controls">
                <h3>ğŸ“¹ ì¹´ë©”ë¼ ì„¤ì •</h3>
                
                <div class="control-group">
                    <label>
                        <input type="checkbox" id="horizontal" {{ 'checked' if flip_settings.horizontal else '' }}>
                        ì¢Œìš° ë°˜ì „
                    </label>
                </div>
                
                <div class="control-group">
                    <label>
                        <input type="checkbox" id="vertical" {{ 'checked' if flip_settings.vertical else '' }}>
                        ìƒí•˜ ë°˜ì „
                    </label>
                </div>
                
                <div class="control-group">
                    <label>íšŒì „:</label>
                    <select id="rotation">
                        <option value="0" {{ 'selected' if flip_settings.rotation == 0 else '' }}>0Â°</option>
                        <option value="90" {{ 'selected' if flip_settings.rotation == 90 else '' }}>90Â°</option>
                        <option value="180" {{ 'selected' if flip_settings.rotation == 180 else '' }}>180Â°</option>
                        <option value="270" {{ 'selected' if flip_settings.rotation == 270 else '' }}>270Â°</option>
                    </select>
                </div>
                
                <button class="btn-primary" onclick="applySettings()">ì¹´ë©”ë¼ ì„¤ì • ì ìš©</button>
                <button class="btn-warning" onclick="resetSettings()">ì „ì²´ ì´ˆê¸°í™”</button>
            </div>
            
            <div id="message" class="status" style="display: none;"></div>
            
            <div class="video-container">
                <h3>ğŸ“º ì‹¤ì‹œê°„ ì´ì¤‘ ê²€ì¶œ ìŠ¤íŠ¸ë¦¬ë°</h3>
                <img src="/video_feed" style="max-width: 100%; border: 2px solid #ddd; border-radius: 8px;">
            </div>
            
            <div class="controls">
                <h3>ğŸ® ë¹ ë¥¸ ì„¤ì •</h3>
                <button class="btn-primary" onclick="setFlip('normal')">ì •ìƒ</button>
                <button class="btn-primary" onclick="setFlip('horizontal')">ì¢Œìš° ë°˜ì „</button>
                <button class="btn-primary" onclick="setFlip('vertical')">ìƒí•˜ ë°˜ì „</button>
                <button class="btn-primary" onclick="setFlip('both')">ìƒí•˜ì¢Œìš° ë°˜ì „</button>
                <button class="btn-primary" onclick="setFlip('rotate180')">180Â° íšŒì „</button>
            </div>
        </div>
        
        <script>
            // ê²€ì¶œ ì„¤ì • ì ìš©
            function applyDetectionSettings() {
                const detection_settings = {
                    yolo_enabled: document.getElementById('yolo_enabled').checked,
                    opencv_enabled: document.getElementById('opencv_enabled').checked,
                    show_fps: document.getElementById('show_fps').checked
                };
                
                fetch('/update_detection_settings', {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify(detection_settings)
                })
                .then(response => response.json())
                .then(data => {
                    showMessage(data.message, data.success ? 'success' : 'error');
                });
            }
            
            // ì¹´ë©”ë¼ ì„¤ì • ì ìš©
            function applySettings() {
                const settings = {
                    horizontal: document.getElementById('horizontal').checked,
                    vertical: document.getElementById('vertical').checked,
                    rotation: parseInt(document.getElementById('rotation').value)
                };
                
                fetch('/update_settings', {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify(settings)
                })
                .then(response => response.json())
                .then(data => {
                    showMessage(data.message, data.success ? 'success' : 'error');
                });
            }
            
            function resetSettings() {
                document.getElementById('horizontal').checked = false;
                document.getElementById('vertical').checked = false;
                document.getElementById('rotation').value = '0';
                document.getElementById('yolo_enabled').checked = true;
                document.getElementById('opencv_enabled').checked = true;
                document.getElementById('show_fps').checked = true;
                applySettings();
                applyDetectionSettings();
            }
            
            function setFlip(type) {
                switch(type) {
                    case 'normal':
                        document.getElementById('horizontal').checked = false;
                        document.getElementById('vertical').checked = false;
                        document.getElementById('rotation').value = '0';
                        break;
                    case 'horizontal':
                        document.getElementById('horizontal').checked = true;
                        document.getElementById('vertical').checked = false;
                        document.getElementById('rotation').value = '0';
                        break;
                    case 'vertical':
                        document.getElementById('horizontal').checked = false;
                        document.getElementById('vertical').checked = true;
                        document.getElementById('rotation').value = '0';
                        break;
                    case 'both':
                        document.getElementById('horizontal').checked = true;
                        document.getElementById('vertical').checked = true;
                        document.getElementById('rotation').value = '0';
                        break;
                    case 'rotate180':
                        document.getElementById('horizontal').checked = false;
                        document.getElementById('vertical').checked = false;
                        document.getElementById('rotation').value = '180';
                        break;
                }
                applySettings();
            }
            
            function showMessage(msg, type) {
                const messageDiv = document.getElementById('message');
                messageDiv.textContent = msg;
                messageDiv.className = 'status ' + type;
                messageDiv.style.display = 'block';
                setTimeout(() => {
                    messageDiv.style.display = 'none';
                }, 3000);
            }
        </script>
    </body>
    </html>
    """
    
    return render_template_string(html_template, 
                                  yolo_status=yolo_status, 
                                  opencv_status=opencv_status,
                                  flip_settings=flip_settings,
                                  detection_settings=detection_settings)

@app.route("/video_feed")
def video_feed():
    return Response(generate_frames(),
                    mimetype="multipart/x-mixed-replace; boundary=frame")

@app.route("/update_settings", methods=["POST"])
def update_settings():
    """ì¹´ë©”ë¼ ë°˜ì „ ì„¤ì • ì—…ë°ì´íŠ¸"""
    try:
        global flip_settings
        data = request.get_json()
        
        # ì„¤ì • ì—…ë°ì´íŠ¸
        flip_settings["horizontal"] = data.get("horizontal", False)
        flip_settings["vertical"] = data.get("vertical", False)
        flip_settings["rotation"] = data.get("rotation", 0)
        
        # ì„¤ì • ì €ì¥
        save_settings()
        
        return jsonify({
            "success": True,
            "message": "ì¹´ë©”ë¼ ì„¤ì •ì´ ì„±ê³µì ìœ¼ë¡œ ì ìš©ë˜ì—ˆìŠµë‹ˆë‹¤!",
            "settings": flip_settings
        })
    except Exception as e:
        return jsonify({
            "success": False,
            "message": f"ì¹´ë©”ë¼ ì„¤ì • ì ìš© ì‹¤íŒ¨: {str(e)}"
        })

@app.route("/update_detection_settings", methods=["POST"])
def update_detection_settings():
    """ê²€ì¶œ ì„¤ì • ì—…ë°ì´íŠ¸"""
    try:
        global detection_settings
        data = request.get_json()
        
        # ì„¤ì • ì—…ë°ì´íŠ¸
        detection_settings["yolo_enabled"] = data.get("yolo_enabled", True)
        detection_settings["opencv_enabled"] = data.get("opencv_enabled", True)
        detection_settings["show_fps"] = data.get("show_fps", True)
        
        # ì„¤ì • ì €ì¥
        save_settings()
        
        return jsonify({
            "success": True,
            "message": "ê²€ì¶œ ì„¤ì •ì´ ì„±ê³µì ìœ¼ë¡œ ì ìš©ë˜ì—ˆìŠµë‹ˆë‹¤!",
            "settings": detection_settings
        })
    except Exception as e:
        return jsonify({
            "success": False,
            "message": f"ê²€ì¶œ ì„¤ì • ì ìš© ì‹¤íŒ¨: {str(e)}"
        })

@app.route("/get_settings")
def get_settings():
    """í˜„ì¬ ì„¤ì • ë°˜í™˜"""
    return jsonify({
        "flip_settings": flip_settings,
        "detection_settings": detection_settings
    })

@app.route("/reset_settings")
def reset_settings():
    """ì„¤ì • ì´ˆê¸°í™”"""
    global flip_settings, detection_settings
    flip_settings = {
        "horizontal": False,
        "vertical": False,
        "rotation": 0
    }
    detection_settings = {
        "yolo_enabled": True,
        "opencv_enabled": True,
        "show_fps": True
    }
    save_settings()
    return jsonify({
        "success": True,
        "message": "ëª¨ë“  ì„¤ì •ì´ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.",
        "flip_settings": flip_settings,
        "detection_settings": detection_settings
    })

@app.route("/status")
def status():
    """ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸"""
    return jsonify({
        "yolo_available": yolo_available,
        "opencv_available": len(opencv_cascades) > 0,
        "model_loaded": model is not None,
        "frame_queue_size": frame_queue.qsize(),
        "processed_queue_size": processed_queue.qsize(),
        "flip_settings": flip_settings,
        "detection_settings": detection_settings,
        "current_fps": current_fps
    })

if __name__ == "__main__":
    print("=== ì‹œìŠ¤í…œ í˜¸í™˜ì„± í™•ì¸ ===")
    
    # NumPy í˜¸í™˜ì„± í™•ì¸
    if not check_numpy_compatibility():
        print("NumPy í˜¸í™˜ì„± ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤. ì¬ì„¤ì¹˜ë¥¼ ê¶Œì¥í•©ë‹ˆë‹¤.")
        print("pip install --upgrade numpy")
    
    # ì„¤ì • ë¡œë“œ
    load_settings()
    
    # YOLO ëª¨ë¸ ì´ˆê¸°í™”
    initialize_yolo_model()
    
    # OpenCV ìºìŠ¤ì¼€ì´ë“œ ì´ˆê¸°í™”
    opencv_available = initialize_opencv_cascades()
    
    # ë°±ê·¸ë¼ìš´ë“œ ìŠ¤ë ˆë“œ ì‹œì‘
    capture_thread = threading.Thread(target=capture_frames, daemon=True)
    process_thread = threading.Thread(target=process_frames, daemon=True)
    
    capture_thread.start()
    process_thread.start()
    
    yolo_status = "í™œì„±í™”ë¨" if yolo_available else "ë¹„í™œì„±í™”ë¨"
    opencv_status = "í™œì„±í™”ë¨" if opencv_available else "ë¹„í™œì„±í™”ë¨"
    
    print(f"YOLO ìƒíƒœ: {yolo_status}")
    print(f"OpenCV ìƒíƒœ: {opencv_status}")
    print("ìŠ¤íŠ¸ë¦¬ë° ì‹œì‘: http://192.168.14.63:5000")
    print("ë¡œì»¬ ì ‘ì†: http://localhost:5000")
    print(f"í˜„ì¬ ë°˜ì „ ì„¤ì •: {flip_settings}")
    print(f"í˜„ì¬ ê²€ì¶œ ì„¤ì •: {detection_settings}")
    print("ğŸ”µ íŒŒë€ìƒ‰ ë°•ìŠ¤: YOLO ê²€ì¶œ ê²°ê³¼")
    print("ğŸ”´ ë¹¨ê°„ìƒ‰ ë°•ìŠ¤: OpenCV ê²€ì¶œ ê²°ê³¼")
    
    app.run(host="0.0.0.0", port=5000, debug=False, threaded=True)