# /home/pi/autocarz/src/8_web_streamer_picamera.py
from flask import Flask, Response, render_template, request, jsonify
from picamera2 import Picamera2
import cv2
import time
import threading
from queue import Queue
import numpy as np
import json
import os

app = Flask(__name__, 
           template_folder='/home/pi/autocarz/templates',
           static_folder='/home/pi/autocarz/static')

# ì „ì—­ ë³€ìˆ˜
model = None
yolo_available = False
opencv_cascades = {}

# ì„¤ì • íŒŒì¼ ê²½ë¡œ
SETTINGS_FILE = "/home/pi/autocarz/camera_settings.json"

# ê¸°ë³¸ ì„¤ì •
flip_settings = {
    "horizontal": False,
    "vertical": False,
    "rotation": 0
}

detection_settings = {
    "yolo_enabled": True,
    "opencv_enabled": True,
    "show_fps": True,
    "resolution": "1024x768",
    "quality": 85,
    "fps_limit": 15
}

# FPS ê³„ì‚°ìš© ë³€ìˆ˜
fps_counter = 0
fps_start_time = time.time()
current_fps = 0

def load_settings():
    """ì„¤ì • íŒŒì¼ì—ì„œ ì„¤ì • ë¡œë“œ"""
    global flip_settings, detection_settings
    try:
        if os.path.exists(SETTINGS_FILE):
            with open(SETTINGS_FILE, 'r', encoding='utf-8') as f:
                loaded_settings = json.load(f)
                if 'flip_settings' in loaded_settings:
                    flip_settings.update(loaded_settings['flip_settings'])
                else:
                    flip_settings.update(loaded_settings)
                
                if 'detection_settings' in loaded_settings:
                    detection_settings.update(loaded_settings['detection_settings'])
                
                print(f"ì„¤ì • ë¡œë“œ ì™„ë£Œ: {flip_settings}")
    except Exception as e:
        print(f"ì„¤ì • ë¡œë“œ ì—ëŸ¬: {e}")

def save_settings():
    """ì„¤ì •ì„ íŒŒì¼ì— ì €ì¥"""
    try:
        os.makedirs(os.path.dirname(SETTINGS_FILE), exist_ok=True)
        settings_data = flip_settings.copy()
        settings_data['detection_settings'] = detection_settings
        
        with open(SETTINGS_FILE, 'w', encoding='utf-8') as f:
            json.dump(settings_data, f, indent=2, ensure_ascii=False)
        print("ì„¤ì • ì €ì¥ ì™„ë£Œ")
    except Exception as e:
        print(f"ì„¤ì • ì €ì¥ ì—ëŸ¬: {e}")

def apply_flip_transform(frame):
    """í”„ë ˆì„ì— ë°˜ì „ ë° íšŒì „ ì ìš©"""
    try:
        if flip_settings["horizontal"]:
            frame = cv2.flip(frame, 1)
        
        if flip_settings["vertical"]:
            frame = cv2.flip(frame, 0)
        
        rotation = flip_settings["rotation"]
        if rotation == 90:
            frame = cv2.rotate(frame, cv2.ROTATE_90_CLOCKWISE)
        elif rotation == 180:
            frame = cv2.rotate(frame, cv2.ROTATE_180)
        elif rotation == 270:
            frame = cv2.rotate(frame, cv2.ROTATE_90_COUNTERCLOCKWISE)
        
        return frame
    except Exception as e:
        print(f"ë°˜ì „ ì ìš© ì—ëŸ¬: {e}")
        return frame

def get_resolution_from_setting():
    """ì„¤ì •ì—ì„œ í•´ìƒë„ ì¶”ì¶œ"""
    resolution_str = detection_settings.get("resolution", "1024x768")
    try:
        width, height = map(int, resolution_str.split('x'))
        return (width, height)
    except:
        return (1024, 768)

def initialize_opencv_cascades():
    """OpenCV Haar Cascade ì´ˆê¸°í™”"""
    global opencv_cascades
    
    try:
        face_cascade_path = cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'
        if os.path.exists(face_cascade_path):
            opencv_cascades['face'] = cv2.CascadeClassifier(face_cascade_path)
            print("OpenCV ì–¼êµ´ ê²€ì¶œ ìºìŠ¤ì¼€ì´ë“œ ë¡œë“œ ì™„ë£Œ")
        
        eye_cascade_path = cv2.data.haarcascades + 'haarcascade_eye.xml'
        if os.path.exists(eye_cascade_path):
            opencv_cascades['eye'] = cv2.CascadeClassifier(eye_cascade_path)
            print("OpenCV ëˆˆ ê²€ì¶œ ìºìŠ¤ì¼€ì´ë“œ ë¡œë“œ ì™„ë£Œ")
        
        print(f"OpenCV ìºìŠ¤ì¼€ì´ë“œ ë¡œë“œ ì™„ë£Œ: {list(opencv_cascades.keys())}")
        return len(opencv_cascades) > 0
        
    except Exception as e:
        print(f"OpenCV ìºìŠ¤ì¼€ì´ë“œ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return False

def opencv_detect_objects(frame_bgr):
    """OpenCVë¡œ ê°ì²´ ê²€ì¶œ"""
    detections = []
    
    try:
        height, width = frame_bgr.shape[:2]
        scale_factor = 0.5 if width > 640 else 1.0
        
        if scale_factor < 1.0:
            small_frame = cv2.resize(frame_bgr, (int(width * scale_factor), int(height * scale_factor)))
        else:
            small_frame = frame_bgr
        
        gray = cv2.cvtColor(small_frame, cv2.COLOR_BGR2GRAY)
        
        for cascade_name, cascade in opencv_cascades.items():
            try:
                objects = cascade.detectMultiScale(
                    gray,
                    scaleFactor=1.1,
                    minNeighbors=5,
                    minSize=(30, 30)
                )
                
                for (x, y, w, h) in objects:
                    if scale_factor < 1.0:
                        x = int(x / scale_factor)
                        y = int(y / scale_factor)
                        w = int(w / scale_factor)
                        h = int(h / scale_factor)
                    
                    detections.append({
                        'bbox': (x, y, x+w, y+h),
                        'class': cascade_name,
                        'confidence': 0.95
                    })
                    
            except Exception as e:
                print(f"OpenCV {cascade_name} ê²€ì¶œ ì—ëŸ¬: {e}")
                
    except Exception as e:
        print(f"OpenCV ê²€ì¶œ ì—ëŸ¬: {e}")
    
    return detections

def draw_yolo_boxes(frame, results):
    """YOLO ê²€ì¶œ ê²°ê³¼ë¥¼ íŒŒë€ìƒ‰ ë°•ìŠ¤ë¡œ ê·¸ë¦¬ê¸° (ì¸ì½”ë”© ë¬¸ì œ í•´ê²°)"""
    try:
        if not results or len(results) == 0:
            return frame
            
        result = results[0]
        
        if result.boxes is None or len(result.boxes) == 0:
            return frame
        
        for box in result.boxes:
            try:
                x1, y1, x2, y2 = box.xyxy[0].cpu().numpy().astype(int)
                conf = float(box.conf[0].cpu().numpy())
                cls_id = int(box.cls[0].cpu().numpy())
                
                # ì¸ì½”ë”© ë¬¸ì œ í•´ê²°: ì˜ì–´ë§Œ ì‚¬ìš©
                label = f"YOLO-Obj{cls_id}: {conf:.2f}"
                
                # íŒŒë€ìƒ‰ ë°•ìŠ¤ ê·¸ë¦¬ê¸°
                cv2.rectangle(frame, (x1, y1), (x2, y2), (255, 0, 0), 2)
                
                (text_width, text_height), baseline = cv2.getTextSize(
                    label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 2
                )
                
                cv2.rectangle(
                    frame,
                    (x1, y1 - text_height - baseline - 5),
                    (x1 + text_width, y1),
                    (255, 0, 0),
                    -1
                )
                
                cv2.putText(
                    frame,
                    label,
                    (x1, y1 - baseline - 2),
                    cv2.FONT_HERSHEY_SIMPLEX,
                    0.5,
                    (255, 255, 255),
                    2
                )
                
            except Exception as box_error:
                print(f"YOLO ë°•ìŠ¤ ê·¸ë¦¬ê¸° ì—ëŸ¬: {box_error}")
                continue
        
        return frame
        
    except Exception as e:
        print(f"YOLO ë°•ìŠ¤ ê·¸ë¦¬ê¸° ì—ëŸ¬: {e}")
        return frame

def draw_opencv_boxes(frame, detections):
    """OpenCV ê²€ì¶œ ê²°ê³¼ë¥¼ ë¹¨ê°„ìƒ‰ ë°•ìŠ¤ë¡œ ê·¸ë¦¬ê¸°"""
    try:
        for detection in detections:
            x1, y1, x2, y2 = detection['bbox']
            class_name = detection['class']
            confidence = detection['confidence']
            
            # ë¹¨ê°„ìƒ‰ ë°•ìŠ¤ ê·¸ë¦¬ê¸°
            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 0, 255), 2)
            
            label = f"CV-{class_name}: {confidence:.2f}"
            
            (text_width, text_height), baseline = cv2.getTextSize(
                label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 2
            )
            
            cv2.rectangle(
                frame,
                (x1, y1 - text_height - baseline - 5),
                (x1 + text_width, y1),
                (0, 0, 255),
                -1
            )
            
            cv2.putText(
                frame,
                label,
                (x1, y1 - baseline - 2),
                cv2.FONT_HERSHEY_SIMPLEX,
                0.5,
                (255, 255, 255),
                2
            )
    
    except Exception as e:
        print(f"OpenCV ë°•ìŠ¤ ê·¸ë¦¬ê¸° ì—ëŸ¬: {e}")
    
    return frame

def initialize_yolo_model():
    """YOLO ëª¨ë¸ ì´ˆê¸°í™”"""
    global model, yolo_available
    
    try:
        from ultralytics import YOLO
        import numpy as np
        
        model_path = "/home/pi/autocarz/models/best.pt"
        if not os.path.exists(model_path):
            print(f"ëª¨ë¸ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {model_path}")
            yolo_available = False
            return
        
        print(f"YOLO ëª¨ë¸ ë¡œë“œ ì‹œë„: {model_path}")
        model = YOLO(model_path)
        model.overrides['verbose'] = False
        model.overrides['device'] = 'cpu'
        model.overrides['half'] = False
        
        # í…ŒìŠ¤íŠ¸ ì¶”ë¡ 
        test_frame = np.zeros((480, 640, 3), dtype=np.uint8)
        test_frame = np.ascontiguousarray(test_frame)
        
        try:
            with np.errstate(all='ignore'):
                test_results = model.predict(
                    test_frame,
                    verbose=False,
                    conf=0.5,
                    device='cpu',
                    half=False
                )
            
            if test_results:
                print("YOLO í…ŒìŠ¤íŠ¸ ì¶”ë¡  ì„±ê³µ!")
                yolo_available = True
                print("YOLO ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
                return
                
        except Exception as inference_error:
            print(f"YOLO ì¶”ë¡  í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {inference_error}")
        
        yolo_available = False
        model = None
        print("YOLO ëª¨ë¸ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨")
        
    except ImportError as e:
        print(f"ultralytics import ì‹¤íŒ¨: {e}")
        yolo_available = False
    except Exception as e:
        print(f"YOLO ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
        yolo_available = False

# ì¹´ë©”ë¼ ì„¤ì •
width, height = get_resolution_from_setting()
picam2 = Picamera2()
picam2.preview_configuration.main.size = (width, height)
picam2.preview_configuration.main.format = "RGB888"
picam2.configure("preview")
picam2.start()
time.sleep(2)

# í”„ë ˆì„ í
frame_queue = Queue(maxsize=2)
processed_queue = Queue(maxsize=2)

def capture_frames():
    """ì¹´ë©”ë¼ì—ì„œ í”„ë ˆì„ì„ ìº¡ì²˜í•˜ëŠ” ìŠ¤ë ˆë“œ"""
    frame_interval = 1.0 / detection_settings["fps_limit"]
    last_capture_time = 0
    
    while True:
        try:
            current_time = time.time()
            if current_time - last_capture_time < frame_interval:
                time.sleep(0.01)
                continue
                
            frame = picam2.capture_array()
            last_capture_time = current_time
            
            if frame is None:
                time.sleep(0.1)
                continue
            
            if not isinstance(frame, np.ndarray):
                frame = np.array(frame)
            
            if frame.dtype != np.uint8:
                if frame.dtype in [np.float32, np.float64] and frame.max() <= 1.0:
                    frame = (frame * 255).astype(np.uint8)
                else:
                    frame = frame.astype(np.uint8)
            
            if len(frame.shape) != 3 or frame.shape[2] != 3:
                continue
            
            if not frame.flags['C_CONTIGUOUS']:
                frame = np.ascontiguousarray(frame)
            
            frame = apply_flip_transform(frame)
            
            if not frame_queue.full():
                frame_queue.put(frame)
            else:
                try:
                    frame_queue.get_nowait()
                    frame_queue.put(frame)
                except:
                    pass
            
        except Exception as e:
            print(f"ì¹´ë©”ë¼ ìº¡ì²˜ ì—ëŸ¬: {e}")
            time.sleep(0.1)

def process_frames():
    """ì´ì¤‘ ê²€ì¶œ ì²˜ë¦¬"""
    global fps_counter, fps_start_time, current_fps
    frame_count = 0
    
    while True:
        if not frame_queue.empty():
            frame = frame_queue.get()
            frame_count += 1
            
            # FPS ê³„ì‚°
            fps_counter += 1
            if time.time() - fps_start_time >= 1.0:
                current_fps = fps_counter
                fps_counter = 0
                fps_start_time = time.time()
            
            try:
                if not isinstance(frame, np.ndarray):
                    frame = np.array(frame, dtype=np.uint8)
                
                if len(frame.shape) != 3 or frame.shape[2] != 3:
                    if not processed_queue.full():
                        processed_queue.put(frame)
                    continue
                
                frame = np.clip(frame, 0, 255).astype(np.uint8)
                
                if not frame.flags['C_CONTIGUOUS']:
                    frame = np.ascontiguousarray(frame)
                
                # RGB to BGR ë³€í™˜
                frame_bgr = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)
                frame_bgr = np.ascontiguousarray(frame_bgr)
                result_frame = frame_bgr.copy()
                
                yolo_count = 0
                opencv_count = 0
                
                # YOLO ê²€ì¶œ (íŒŒë€ìƒ‰)
                if detection_settings["yolo_enabled"] and yolo_available and model is not None:
                    try:
                        with np.errstate(all='ignore'):
                            results = model.predict(
                                frame_bgr,
                                verbose=False,
                                conf=0.5,
                                device='cpu',
                                half=False
                            )
                        
                        if results and len(results) > 0:
                            result_frame = draw_yolo_boxes(result_frame, results)
                            if results[0].boxes is not None:
                                yolo_count = len(results[0].boxes)
                            
                    except Exception as yolo_error:
                        if frame_count % 100 == 0:
                            print(f"YOLO ì¶”ë¡  ì—ëŸ¬: {yolo_error}")
                
                # OpenCV ê²€ì¶œ (ë¹¨ê°„ìƒ‰)
                if detection_settings["opencv_enabled"] and len(opencv_cascades) > 0:
                    try:
                        opencv_detections = opencv_detect_objects(result_frame)
                        opencv_count = len(opencv_detections)
                        
                        if opencv_detections:
                            result_frame = draw_opencv_boxes(result_frame, opencv_detections)
                            
                    except Exception as opencv_error:
                        if frame_count % 100 == 0:
                            print(f"OpenCV ê²€ì¶œ ì—ëŸ¬: {opencv_error}")
                
                # FPS ë° ê²€ì¶œ ì •ë³´ í‘œì‹œ
                if detection_settings["show_fps"]:
                    cv2.putText(result_frame, f"FPS: {current_fps}", (10, 30), 
                              cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
                    
                    info_text = f"YOLO(Blue): {yolo_count} | OpenCV(Red): {opencv_count}"
                    cv2.putText(result_frame, info_text, (10, 60), 
                              cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)
                
                # BGR to RGB ë³€í™˜
                result_frame = cv2.cvtColor(result_frame, cv2.COLOR_BGR2RGB)
                result_frame = np.ascontiguousarray(result_frame)
                
                if not processed_queue.full():
                    processed_queue.put(result_frame)
                else:
                    try:
                        processed_queue.get_nowait()
                        processed_queue.put(result_frame)
                    except:
                        pass
                        
            except Exception as e:
                if frame_count % 100 == 0:
                    print(f"í”„ë ˆì„ ì²˜ë¦¬ ì—ëŸ¬: {e}")
                
                if not processed_queue.full():
                    processed_queue.put(frame)
        
        time.sleep(0.01)

def generate_frames():
    """ì›¹ ìŠ¤íŠ¸ë¦¬ë°ìš© í”„ë ˆì„ ìƒì„±"""
    while True:
        if not processed_queue.empty():
            annotated_frame = processed_queue.get()
            
            try:
                frame_bgr = cv2.cvtColor(annotated_frame, cv2.COLOR_RGB2BGR)
                
                encode_param = [cv2.IMWRITE_JPEG_QUALITY, detection_settings["quality"]]
                success, buffer = cv2.imencode(".jpg", frame_bgr, encode_param)
                
                if success:
                    frame_bytes = buffer.tobytes()
                    yield (b"--frame\r\n"
                           b"Content-Type: image/jpeg\r\n\r\n" + frame_bytes + b"\r\n")
            except Exception as e:
                print(f"í”„ë ˆì„ ì¸ì½”ë”© ì—ëŸ¬: {e}")
        else:
            time.sleep(0.01)

# ============= Flask ë¼ìš°íŠ¸ =============

@app.route("/")
def index():
    """ë©”ì¸ í˜ì´ì§€ - ì´ì œ í…œí”Œë¦¿ íŒŒì¼ ì‚¬ìš©"""
    yolo_status = "í™œì„±í™”ë¨" if yolo_available else "ë¹„í™œì„±í™”ë¨"
    opencv_status = "í™œì„±í™”ë¨" if len(opencv_cascades) > 0 else "ë¹„í™œì„±í™”ë¨"
    
    return render_template('index.html', 
                          yolo_status=yolo_status, 
                          opencv_status=opencv_status,
                          flip_settings=flip_settings,
                          detection_settings=detection_settings)

@app.route("/video_feed")
def video_feed():
    return Response(generate_frames(),
                    mimetype="multipart/x-mixed-replace; boundary=frame")

@app.route("/update_settings", methods=["POST"])
def update_settings():
    """ì¹´ë©”ë¼ ë°˜ì „ ì„¤ì • ì—…ë°ì´íŠ¸"""
    try:
        global flip_settings
        data = request.get_json()
        
        flip_settings["horizontal"] = data.get("horizontal", False)
        flip_settings["vertical"] = data.get("vertical", False)
        flip_settings["rotation"] = data.get("rotation", 0)
        
        save_settings()
        
        return jsonify({
            "success": True,
            "message": "ì¹´ë©”ë¼ ì„¤ì •ì´ ì„±ê³µì ìœ¼ë¡œ ì ìš©ë˜ì—ˆìŠµë‹ˆë‹¤!",
            "settings": flip_settings
        })
    except Exception as e:
        return jsonify({
            "success": False,
            "message": f"ì¹´ë©”ë¼ ì„¤ì • ì ìš© ì‹¤íŒ¨: {str(e)}"
        })

@app.route("/update_detection_settings", methods=["POST"])
def update_detection_settings():
    """ê²€ì¶œ ì„¤ì • ì—…ë°ì´íŠ¸"""
    try:
        global detection_settings
        data = request.get_json()
        
        detection_settings["yolo_enabled"] = data.get("yolo_enabled", True)
        detection_settings["opencv_enabled"] = data.get("opencv_enabled", True)
        detection_settings["show_fps"] = data.get("show_fps", True)
        detection_settings["quality"] = data.get("quality", 85)
        detection_settings["fps_limit"] = data.get("fps_limit", 15)
        
        save_settings()
        
        return jsonify({
            "success": True,
            "message": "ê²€ì¶œ ì„¤ì •ì´ ì„±ê³µì ìœ¼ë¡œ ì ìš©ë˜ì—ˆìŠµë‹ˆë‹¤!",
            "settings": detection_settings
        })
    except Exception as e:
        return jsonify({
            "success": False,
            "message": f"ê²€ì¶œ ì„¤ì • ì ìš© ì‹¤íŒ¨: {str(e)}"
        })

@app.route("/status")
def status():
    """ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸"""
    return jsonify({
        "yolo_available": yolo_available,
        "opencv_available": len(opencv_cascades) > 0,
        "model_loaded": model is not None,
        "frame_queue_size": frame_queue.qsize(),
        "processed_queue_size": processed_queue.qsize(),
        "flip_settings": flip_settings,
        "detection_settings": detection_settings,
        "current_fps": current_fps
    })

if __name__ == "__main__":
    print("=== ì‹œìŠ¤í…œ ì´ˆê¸°í™” ===")
    
    # ì„¤ì • ë¡œë“œ
    load_settings()
    
    # YOLO ëª¨ë¸ ì´ˆê¸°í™”
    initialize_yolo_model()
    
    # OpenCV ìºìŠ¤ì¼€ì´ë“œ ì´ˆê¸°í™”
    opencv_available = initialize_opencv_cascades()
    
    # ë°±ê·¸ë¼ìš´ë“œ ìŠ¤ë ˆë“œ ì‹œì‘
    capture_thread = threading.Thread(target=capture_frames, daemon=True)
    process_thread = threading.Thread(target=process_frames, daemon=True)
    
    capture_thread.start()
    process_thread.start()
    
    yolo_status = "í™œì„±í™”ë¨" if yolo_available else "ë¹„í™œì„±í™”ë¨"
    opencv_status = "í™œì„±í™”ë¨" if opencv_available else "ë¹„í™œì„±í™”ë¨"
    
    print(f"YOLO ìƒíƒœ: {yolo_status}")
    print(f"OpenCV ìƒíƒœ: {opencv_status}")
    print("ìŠ¤íŠ¸ë¦¬ë° ì‹œì‘: http://192.168.14.63:5000")
    print("ğŸ”µ íŒŒë€ìƒ‰ ë°•ìŠ¤: YOLO ê²€ì¶œ ê²°ê³¼")
    print("ğŸ”´ ë¹¨ê°„ìƒ‰ ë°•ìŠ¤: OpenCV ê²€ì¶œ ê²°ê³¼")
    
    app.run(host="0.0.0.0", port=5000, debug=False, threaded=True)